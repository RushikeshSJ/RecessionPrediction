{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RushikeshSJ/RecessionPrediction/blob/main/Optimized_Code_of_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Library**"
      ],
      "metadata": {
        "id": "SJm5ZuvFjfLh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8RduBXpjWBY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Importing From Drive**"
      ],
      "metadata": {
        "id": "cazT4n8vjtMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "9Nj8JgWHj1rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Algorithm**"
      ],
      "metadata": {
        "id": "aLxj0_bAkNge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link='https://docs.google.com/spreadsheets/d/15GLD643gjeVgXfdlje0XKhsG73rpCDcB/edit?usp=drive_link&ouid=101584034968865748275&rtpof=true&sd=true'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# to get the id part of the file\n",
        "id = link.split(\"/\")[-2]\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "#downloaded.GetContentFile('Colab_2023_FebTest.csv')\n",
        "\n",
        "downloaded.GetContentFile('Final Project Data.xlsx')\n",
        "data = pd.read_excel('Final Project Data.xlsx')"
      ],
      "metadata": {
        "id": "fmadl9KPkQPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Imbalance**"
      ],
      "metadata": {
        "id": "EszeE414kiqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = data[\"Recession\"].value_counts()\n",
        "c1 = value_counts.iloc[0]# No Recession\n",
        "c2 = value_counts.iloc[1]# For Recession\n",
        "print(value_counts)\n",
        "print(\"Makes Minority Class up {} %\".format(round(c2/c1 * 100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT8Vd_mxkXUn",
        "outputId": "48f6ce4d-4039-4b86-a799-f25fed3348b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    23\n",
            "0    19\n",
            "Name: Recession, dtype: int64\n",
            "Makes Minority Class up 82.61 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.The script is creating a variable called \"value_counts\" by using the pandas \"value_counts()\" method on the \"Recession\" column of a pandas dataframe called \"data\".\n",
        "2. The script is then creating two variables, \"c1\" and \"c2\", which represent the count of the first and second most common values in the \"Recession\" column, respectively.\n",
        "3. Finally, the script is printing the \"value_counts\" variable and the percentage of the minority class in the \"Recession\" column.\n",
        "\n",
        "Assuming that the \"Recession\" column contains binary data (e.g. 0 for no recession and 1 for a recession), the code is calculating the percentage of the minority class (i.e. the less common class) in the \"Recession\" column. Specifically, it is calculating the percentage of the second most common class (represented by \"c2\") relative to the most common class (represented by \"c1\").\n",
        "\n",
        "The output of this script will be the value counts of the \"Recession\" column (i.e. the number of times each value appears), followed by a string indicating what percentage of the minority class is represented in the data. The percentage will be rounded to two decimal places."
      ],
      "metadata": {
        "id": "faWFRJabIT2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are a total of {} Quarterly of recession in this data\".format(data[\"Recession\"].sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZRVykvBkyYl",
        "outputId": "c25f2818-10d6-4c4f-fdcd-9adba7da3db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are a total of 23 Quarterly of recession in this data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get x and y\n",
        "X = data.drop(['Recession'], axis=1)\n",
        "y = data[\"Recession\"]"
      ],
      "metadata": {
        "id": "OdYicccpk4AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The script is creating a new dataframe called \"X\" by dropping the \"Recession\" column from an existing dataframe called \"data\".\n",
        "2. The script is creating a new pandas series called \"y\" that contains only the values from the \"Recession\" column of the original \"data\" dataframe.\n",
        "\n",
        "Assuming that the \"Recession\" column contains the target variable that the model aims to predict, these two lines of code are separating the input features (i.e. independent variables) from the target variable (i.e. dependent variable) in the dataset.\n",
        "\n",
        "The resulting \"X\" dataframe will have the same number of rows as the original \"data\" dataframe, but one less column (since the \"Recession\" column has been removed). This \"X\" dataframe can then be used as input to train a machine learning model to predict the \"Recession\" target variable.\n",
        "\n",
        "The resulting \"y\" series will contain only the values from the \"Recession\" column, which can be used as the target variable in machine learning algorithms.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uORDfTQpJQrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the modeling dataset**"
      ],
      "metadata": {
        "id": "C_X-rUl3k931"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification"
      ],
      "metadata": {
        "id": "EfZT2jMhlCkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make_classification() is a function that generates a random n-class classification problem. This function is useful for testing machine learning models on datasets with known properties.\n",
        "\n",
        "Once imported, the make_classification() function can be called to generate a synthetic classification dataset, which can then be used to test and evaluate machine learning models."
      ],
      "metadata": {
        "id": "5xrqkh8zK44M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data processing**"
      ],
      "metadata": {
        "id": "pP3h8Z2HlHXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9NR86aiFlOaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data visualization**"
      ],
      "metadata": {
        "id": "sn3vhrimlUc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "WN77DeLmlWRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. matplotlib.pyplot is a Python library used for data visualization. It provides a simple and easy-to-use interface for creating a wide range of charts and plots, including line plots, bar plots, scatter plots, histograms, and more. pyplot is a module within the matplotlib library that provides a collection of functions that can be used to create a variety of visualizations with just a few lines of code.\n",
        "\n",
        "2. seaborn is another Python library used for data visualization that is built on top of matplotlib. It provides a higher-level interface than matplotlib and allows for the creation of more complex and aesthetically pleasing visualizations with less code.\n",
        "  To use seaborn, you typically start by importing the library with import seaborn as sns. Then you can use the various functions provided by seaborn to create your visualization, customize it, and save it as an image file or display it on the screen. It's often used in combination with pandas, a popular data manipulation library, for loading and preprocessing data before visualization."
      ],
      "metadata": {
        "id": "aRgtecH5MXu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model and performance**"
      ],
      "metadata": {
        "id": "PrDmJbQmldGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "A7u_31Khlfj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The train_test_split function is used to split a dataset into two or more subsets, typically a training set and a testing set, that can be used for training and evaluating a machine learning model, respectively. It takes a dataset (usually in the form of NumPy arrays or Pandas DataFrames), along with a set of options for how to split the data, such as the size of the testing set, whether to shuffle the data before splitting, and whether to use a random seed for reproducibility.\n",
        "\n",
        "2. A random forest is an ensemble learning method that builds a collection of decision trees and combines their predictions to produce a final output. The random forest algorithm builds multiple decision trees using a randomly selected subset of features and a randomly selected subset of the training data.\n",
        "\n",
        "The RandomForestClassifier class is used for classification tasks, where the goal is to predict a categorical output variable based on a set of input features.\n",
        "\n",
        "3.classification_report is a function provided by the scikit-learn library (sklearn) that is used to generate a classification report for a machine learning model's performance on a test dataset.\n",
        "\n",
        "The classification report provides a summary of different evaluation metrics for a classification model, such as precision, recall, and F1-score, for each class in the target variable. These metrics are useful for evaluating the performance of a classification model and identifying areas where the model may be underperforming."
      ],
      "metadata": {
        "id": "XKc1OrYiM7Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversampling and under sampling**"
      ],
      "metadata": {
        "id": "VA5HU8yXlmpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "Jvh-8ejslpcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **RandomOverSampler** randomly duplicates samples from the minority class to increase its size. It does not create new synthetic samples like SMOTE, but simply oversamples the minority class by randomly replicating existing samples until the classes are balanced.\n",
        "\n",
        "2.**SMOTE (Synthetic Minority Over-sampling Technique)** creates synthetic samples for the minority class by generating new samples that are similar to existing minority class samples. SMOTE selects samples from the minority class and creates synthetic samples by interpolating between the features of each selected sample and its k nearest minority class neighbors.\n",
        "\n",
        "3.**RandomUnderSampler** randomly removes samples from the majority class to decrease its size. It does not consider the distribution of samples in the feature space, and can therefore result in loss of useful information.\n",
        "\n",
        "4.**NearMiss** is an undersampling technique that selects samples from the majority class that are close to the minority class.\n",
        "\n",
        "5.The **Counter** class is a standard Python library class that is used to count the frequency of items in an iterable. It returns a dictionary where the keys are the items in the iterable and the values are the count of each item."
      ],
      "metadata": {
        "id": "-sC2-gcLPEyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train test split**"
      ],
      "metadata": {
        "id": "UNSbR53Ylw42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
      ],
      "metadata": {
        "id": "1pcAoxKslyzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. X: The feature matrix of the dataset.\n",
        "2. y: The target vector of the dataset.\n",
        "3. test_size: The proportion of the dataset to include in the testing set. The value should be between 0 and 1. For example, test_size=0.2 means that 20% of the dataset will be used for testing.\n",
        "4. random_state: The random seed used by the random number generator. The same value of random_state will produce the same results each time the function is run. If random_state is not specified, the function will use a different random seed each time it is run\n",
        "\n",
        "**X_train:** The feature matrix of the training set.\n",
        "**X_test:** The feature matrix of the testing set.\n",
        "**y_train:** The target vector of the training set.\n",
        "**y_test:** The target vector of the testing set."
      ],
      "metadata": {
        "id": "fYCWfYU_QoiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check the number of records**"
      ],
      "metadata": {
        "id": "FSkgRtI6l45O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = X_train.shape[0]\n",
        "n_test = X_test.shape[0]\n",
        "counts = sorted(Counter(y_train).items())\n",
        "majority_class_count = counts[0][1]\n",
        "minority_class_count = counts[1][1]\n",
        "\n",
        "print(f\"The number of records in the training dataset is {n_train}\")\n",
        "print(f\"The number of records in the test dataset is {n_test}\")\n",
        "print(f\"The training dataset has {majority_class_count} records for the majority class and {minority_class_count} records for the minority class.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1maYMfWl7Ds",
        "outputId": "11f64b53-178d-4ea0-baec-7a4f6880c3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of records in the training dataset is 33\n",
            "The number of records in the test dataset is 9\n",
            "The training dataset has 17 records for the majority class and 16 records for the minority class.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**X_train.shape[0]** returns the number of rows in the X_train array, while **X_test.shape[0]** returns the number of rows in the X_test array.\n",
        "\n",
        "**Counter(y_train)** creates a dictionary that counts the number of occurrences of each class in the y_train array.\n",
        "\n",
        "**sorted()** function sorts the dictionary items by keys in ascending order.\n",
        "\n",
        "The .**items()** method returns a list of tuples, where each tuple contains a key-value pair from the dictionary.\n",
        "\n",
        "**counts[0][1]** is the first tuple in the counts list, which corresponds to the class label with the smallest value (assuming the class labels are integers).\n",
        "\n",
        "**counts[1][1]** accesses the second element of the second tuple, which is the count of the minority class in y_train."
      ],
      "metadata": {
        "id": "7IBoSae9RXoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling techniques**"
      ],
      "metadata": {
        "id": "Kn8Q6I1ZmCUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# initialize resampling methods\n",
        "sm = SMOTE(random_state=12)\n",
        "rus = RandomUnderSampler(random_state=12)\n",
        "\n",
        "# resample training data\n",
        "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
        "X_train_rnd, y_train_rnd  = rus.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "v4OZqM9SmHfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. sm is an instance of the SMOTE class from the imblearn.over_sampling module. It is initialized with a random_state of 12, which ensures that the results of the oversampling are reproducible.\n",
        "2. rus is an instance of the RandomUnderSampler class with a random_state of 12. This ensures that the results of the under-sampling are reproducible.\n",
        "\n",
        "SMOTE class is created with a random_state of 12, and an instance of the RandomUnderSampler class is created with the same random_state. The fit_resample method is then called on each of these resampling methods, using the training data X_train and y_train as arguments. The resulting oversampled training data is stored in X_train_smote and y_train_smote, while the resulting undersampled training data is stored in X_train_rnd and y_train_rnd"
      ],
      "metadata": {
        "id": "62NnZ1FPVOhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_pairs = {\"Normal\":(X_train, y_train),\n",
        "                    \"SMOTE\":(X_train_smote, y_train_smote),\n",
        "                    \"Random Undersampling\":(X_train_rnd, y_train_rnd)}"
      ],
      "metadata": {
        "id": "uSMM-05vmOa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creates a dictionary called train_test_pairs which contains three key-value pairs. Each key represents a resampling method applied to the training data, and its corresponding value contains a tuple of the resampled training data and labels.\n",
        "\n",
        "The three resampling methods used here are:\n",
        "\n",
        "**\"Normal\":** The original training data without any resampling.\n",
        "\n",
        "**\"SMOTE\":** Synthetic Minority Over-sampling Technique, which generates synthetic samples of the minority class to balance the class distribution.\n",
        "\n",
        "**\"Random Undersampling\":** Randomly selects a subset of samples from the majority class to balance the class distribution.\n",
        "\n",
        "The resulting train_test_pairs dictionary will be used to fit and evaluate multiple models with different resampled training data."
      ],
      "metadata": {
        "id": "ops9yWmFXfD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithm Library Importing**"
      ],
      "metadata": {
        "id": "Uc391sIDmSTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly as plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "D4iVR0S8mae4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Array For Dataset**"
      ],
      "metadata": {
        "id": "tp08H4rpmgQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = {\"Logistic Regression\": LogisticRegression(),\n",
        "       \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
        "       \"Random Forest\": RandomForestClassifier(max_depth=15,\n",
        "                                                      n_estimators=200,\n",
        "                                                      class_weight = \"balanced_subsample\",\n",
        "                                                      random_state=12)}"
      ],
      "metadata": {
        "id": "cZSIrNaimd70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates a dictionary called clfs which contains three key-value pairs. Each key represents a different classifier to be used in the modeling process, and its corresponding value is the corresponding classifier object instantiated using the default hyperparameters.\n",
        "\n",
        "1. **max_depth=15:** The maximum depth of each tree in the forest is set to 15.\n",
        "2. **n_estimators=200:** The number of trees in the forest is set to 200.\n",
        "3. **class_weight =** \"balanced_subsample\": The class weights are set to \"balanced_subsample\", which is a method of balancing the class distribution within each bootstrap sample.\n",
        "4. **random_state=12:** The random seed is set to 12 to ensure reproducibility."
      ],
      "metadata": {
        "id": "sHlShKg6X2q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Fitting**"
      ],
      "metadata": {
        "id": "fkSRYBO_moaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clfs = {\"Logistic Regression\": LogisticRegression(),\n",
        "        \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
        "        \"Random Forest\": RandomForestClassifier(max_depth=15,\n",
        "                                                 n_estimators=200,\n",
        "                                                 class_weight=\"balanced_subsample\",\n",
        "                                                 random_state=12)}"
      ],
      "metadata": {
        "id": "Z8e6-YUommDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**plotly.graph_objects** is imported as go which will be used to create interactive visualizations of the ROC curves.(An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate. False Positive Rate.)\n",
        "\n",
        "accuracy_score, roc_curve, and roc_auc_score are imported from sklearn.metrics which will be used to compute and evaluate the performance of each classifier.\n",
        "\n"
      ],
      "metadata": {
        "id": "r2tsbsoXYomL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "for name, clf in clfs.items():\n",
        "    clf.fit(X_train_rnd, y_train_rnd)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "    auc = roc_auc_score(y_test, clf.predict(X_test))\n",
        "    print(f\"Recession Predicted %: {(accuracy_score(y_test,y_pred))*100:.2f}\");\n",
        "    name = f\"{name} (AUC={auc:.2f})\"\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))"
      ],
      "metadata": {
        "id": "PS7fF-Kom1dJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac25342-5fda-4096-846e-88d38d8cd28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recession Predicted %: 33.33\n",
            "Recession Predicted %: 88.89\n",
            "Recession Predicted %: 88.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **go.Figure()** initializes an empty figure object to which the ROC curves will be added.\n",
        "2. **add_shape()** is used to add a diagonal line that represents the ROC curve of a random classifier that guesses randomly between the two classes.\n",
        "3. The **for loop **iterates over each classifier in clfs. For each classifier, the model is fitted to the training data using the Random UnderSampler, and predictions are made on the test set. The **roc_curve()** function is used to compute the **false positive rate (fpr)** and **true positive rate (tpr)** for each threshold.\n",
        "4. The roc_auc_score() function is used to compute the AUC score for each classifier.\n",
        "5. The name of the classifier is updated to include the AUC score, and a Scatter object is added to the figure for each classifier with the fpr and tpr as the x and y values, respectively."
      ],
      "metadata": {
        "id": "wJIA8nYCZLys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig.update_layout(\n",
        "    xaxis_title='False Positive Rate',\n",
        "    yaxis_title='True Positive Rate',\n",
        "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
        "    xaxis=dict(constrain='domain'),\n",
        "    width=900, height=700\n",
        ")\n",
        "fig.update_layout(title_text=\"Comparing different models\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "geNPKVEtnCX2",
        "outputId": "3f90438d-7cdc-44ee-ba5f-04c678906fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"7eecf55f-ad8c-4e98-895e-9c27e5a4c314\" class=\"plotly-graph-div\" style=\"height:700px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7eecf55f-ad8c-4e98-895e-9c27e5a4c314\")) {                    Plotly.newPlot(                        \"7eecf55f-ad8c-4e98-895e-9c27e5a4c314\",                        [{\"mode\":\"lines\",\"name\":\"Logistic Regression (AUC=0.39)\",\"x\":[0.0,0.0,0.0,0.5,0.5,1.0,1.0],\"y\":[0.0,0.14285714285714285,0.2857142857142857,0.2857142857142857,0.5714285714285714,0.5714285714285714,1.0],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Decision Tree (AUC=0.93)\",\"x\":[0.0,0.0,1.0],\"y\":[0.0,0.8571428571428571,1.0],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Random Forest (AUC=0.93)\",\"x\":[0.0,0.0,0.0,1.0],\"y\":[0.0,0.2857142857142857,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"yaxis\":{\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"xaxis\":{\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"width\":900,\"height\":700,\"title\":{\"text\":\"Comparing different models\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7eecf55f-ad8c-4e98-895e-9c27e5a4c314');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotly library to generate an ROC curve plot for three different classification models: Logistic Regression, Decision Tree, and Random Forest. The ROC curve is a graphical representation of the performance of a binary classifier system as its discrimination threshold is varied.\n",
        "\n",
        "The code first initializes the three classification models and defines a dictionary containing the models as values and their names as keys. It then creates a Plotly figure and adds a diagonal dashed line to represent a random classifier. Next, it loops over the models and for each one, fits it on the training data with Random Undersampling, makes predictions on the test data, calculates the false positive rate (fpr), true positive rate (tpr), and area under the curve (auc), and adds a line trace to the figure.\n",
        "\n",
        "The code first initializes the three classification models and defines a dictionary containing the models as values and their names as keys. It then creates a Plotly figure and adds a diagonal dashed line to represent a random classifier. Next, it loops over the models and for each one, fits it on the training data with Random Undersampling, makes predictions on the test data, calculates the false positive rate (fpr), true positive rate (tpr), and area under the curve (auc), and adds a line trace to the figure."
      ],
      "metadata": {
        "id": "thyCLz49Z2-t"
      }
    }
  ]
}